# sparkML
ML based on Spark

Set Up Requirements:

1. Download Java
2. Set JAVA_HOME
3. Add %JAVA_HOME%\bin to PATH. Check by typing java -version in command prompt.
4. Download Python and select this as the puthon kernel for you Jupyter notebooks
5. Check the spark and java versions compatibility matrix at https://community.cloudera.com/t5/Community-Articles/Spark-and-Java-versions-Supportability-Matrix/ta-p/383669
6. Download spark with hadoop from Apache Spark page. Extract it.
7. Set this as your SPARK_HOME
8. Start spark server by running ./bin/pyspark in Spark directory.
9. Guide for Spark set up: https://spark.apache.org/docs/latest/quick-start.html
10. Note: Used JDK 17 with PySpark 4.0.0 (spark-4.0.0-bin-hadoop3 as the spark server)