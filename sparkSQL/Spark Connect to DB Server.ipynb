{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbcbef64",
   "metadata": {},
   "source": [
    "## Python/Spark Notebook code with SQL to query data from SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3cd87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"Query SQL Server\").getOrCreate()\n",
    "\n",
    "# Define the SQL query\n",
    "query = \"(SELECT * FROM table1 JOIN table2 ON table1.id = table2.id) AS joined_tables\"\n",
    "\n",
    "# Define the connection properties\n",
    "connectionProperties = {\n",
    "  \"user\": \"<username>\",\n",
    "  \"password\": \"<password>\",\n",
    "  \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "}\n",
    "\n",
    "# Define the JDBC URL\n",
    "jdbcUrl = \"jdbc:sqlserver://<server>:<port>;database=<database>\"\n",
    "\n",
    "# Load the data into a dataframe\n",
    "df = spark.read.jdbc(url=jdbcUrl, table=query, properties=connectionProperties)\n",
    "\n",
    "# Save the dataframe to a Gen2 data set\n",
    "df.write.format(\"com.databricks.spark.avro\").option(\"compression\", \"snappy\").mode(\"overwrite\").save(\"<Gen2 datalake set path>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030422d1",
   "metadata": {},
   "source": [
    "In this code snippet, replace username, password, server, port, database, and Gen2 data set path with your specific values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
